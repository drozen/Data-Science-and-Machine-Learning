{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data\\train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data\\train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"/tmp/data\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.contrib.learn.python.learn.datasets.base.Datasets"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape #np array of # of images ... with 784 bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = mnist.train.images[1].reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26d0de6be80>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26d0b450a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sample,cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001 # says how quickly we want to apply the optimization function\n",
    "training_epochs = 30 # # training cycles\n",
    "batch_size = 100 # size of batches of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_classes = 10  # network parameters\n",
    "n_sample = mnist.train.num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_input = 784 # 28*28 flattened image array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden_1 = 256\n",
    "n_hidden_2 = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x,weights,biases):\n",
    "    '''\n",
    "    x: Placeholder for Data Input\n",
    "    weights: Dict of weights\n",
    "    biases: Dict of bias values\n",
    "    '''\n",
    "    \n",
    "    # First Hidden Layer with RELU Activation Function\n",
    "    # X * weight + bias value\n",
    "    layer_1 = tf.add(tf.matmul(x,weights['h1']),biases['b1'])\n",
    "    # RELU( X * weight + bias value) -> f(x) = max(0,x)\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    \n",
    "    # Second Hidden Layer\n",
    "    layer_2 = tf.add(tf.matmul(layer_1,weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    \n",
    "    # Last Output Layer\n",
    "    out_layer = tf.matmul(layer_2,weights['out']) + biases['out']\n",
    "    \n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = { # weights dict\n",
    "    'h1':tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2':tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out':tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "biases = { # weights dict\n",
    "    'b1':tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2':tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out':tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder('float',[None,n_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y= tf.placeholder('float',[None,n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = multilayer_perceptron(x,weights,biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred,labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = mnist.train.next_batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.01176471,  0.16470589,\n",
       "         0.52156866,  0.68235296,  0.99607849,  0.99607849,  0.5411765 ,\n",
       "         0.52549022,  0.52156866,  0.52156866,  0.43529415,  0.01568628,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.01568628,  0.49803925,  0.99215692,  0.99215692,  0.99215692,\n",
       "         0.99215692,  0.99215692,  0.99215692,  0.99607849,  0.99215692,\n",
       "         0.99215692,  0.99215692,  0.57647061,  0.02352941,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.21176472,  0.99215692,\n",
       "         0.99215692,  0.99215692,  0.99215692,  0.99215692,  0.99215692,\n",
       "         0.99215692,  0.99607849,  0.99215692,  0.99215692,  0.99215692,\n",
       "         0.99215692,  0.52941179,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.6156863 ,  0.99215692,  0.99215692,  0.80000007,\n",
       "         0.32941177,  0.32941177,  0.32941177,  0.32941177,  0.33333334,\n",
       "         0.32941177,  0.62352943,  0.83921576,  0.99215692,  0.76078439,\n",
       "         0.19215688,  0.02745098,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.6156863 ,\n",
       "         0.99215692,  0.99215692,  0.70588237,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.03529412,\n",
       "         0.60784316,  0.99215692,  0.99215692,  0.99215692,  0.14117648,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.6156863 ,  0.99215692,  0.99215692,\n",
       "         0.70588237,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.01568628,  0.33333334,  0.79215693,  0.99215692,  0.99215692,\n",
       "         0.99215692,  0.99215692,  0.14117648,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.6156863 ,  0.99215692,  0.99215692,  0.70588237,  0.        ,\n",
       "         0.        ,  0.        ,  0.16078432,  0.81960791,  0.99215692,\n",
       "         0.99215692,  0.99215692,  0.99215692,  0.89803928,  0.65882355,\n",
       "         0.09411766,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.6156863 ,  0.99215692,\n",
       "         0.99215692,  0.70588237,  0.        ,  0.        ,  0.37254903,\n",
       "         0.92156869,  0.99607849,  0.99215692,  0.99215692,  0.92156869,\n",
       "         0.50196081,  0.10196079,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.18823531,  0.99215692,  0.99215692,  0.96862751,\n",
       "         0.51372552,  0.83529419,  0.94117653,  0.99215692,  0.99607849,\n",
       "         0.74901962,  0.27058825,  0.07450981,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.00784314,\n",
       "         0.45490199,  0.99215692,  0.99215692,  0.99215692,  0.99215692,\n",
       "         0.99215692,  0.99215692,  0.50196081,  0.01960784,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.69411767,\n",
       "         0.99607849,  0.99607849,  0.99607849,  0.99607849,  0.76862752,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.2392157 ,  0.99215692,  0.99215692,\n",
       "         0.99215692,  0.99215692,  0.99215692,  0.57254905,  0.29019609,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.53333336,  0.99215692,  0.99215692,  0.99215692,  0.99215692,\n",
       "         0.99215692,  0.99607849,  0.95686281,  0.54901963,  0.0509804 ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.71372551,  0.99215692,\n",
       "         0.99215692,  0.42352945,  0.53333336,  0.89411771,  0.99607849,\n",
       "         0.99215692,  0.99215692,  0.77254909,  0.18823531,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.71372551,  0.99215692,  0.99215692,  0.14117648,\n",
       "         0.        ,  0.13725491,  0.76862752,  0.99215692,  0.99215692,\n",
       "         0.99215692,  0.67843139,  0.05882353,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.71372551,\n",
       "         0.99215692,  0.99215692,  0.14117648,  0.        ,  0.        ,\n",
       "         0.01176471,  0.53333336,  0.99215692,  0.99215692,  0.99215692,\n",
       "         0.23529413,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.71372551,  0.99215692,  0.99215692,\n",
       "         0.42745101,  0.03137255,  0.        ,  0.        ,  0.25490198,\n",
       "         0.99215692,  0.99215692,  0.99215692,  0.23529413,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.52941179,  0.99215692,  0.99215692,  0.99215692,  0.86666673,\n",
       "         0.85490203,  0.8588236 ,  0.9333334 ,  0.99215692,  0.99215692,\n",
       "         0.90196085,  0.14509805,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.02352941,  0.57647061,\n",
       "         0.99215692,  0.99215692,  0.99215692,  0.99215692,  0.99607849,\n",
       "         0.99215692,  0.99215692,  0.99215692,  0.32549021,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.14901961,  0.51764709,  0.92549026,\n",
       "         0.99215692,  0.99215692,  0.99607849,  0.99215692,  0.92549026,\n",
       "         0.20392159,  0.01568628,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xsamp, ysamp = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26d0f586ef0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nivADQRF+IKj/B3vsVdyiAKCgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26d0df54e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(Xsamp.reshape(28,28), cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ysamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Session\n",
    "#### now can do everything with sess, without haveing to have it all under the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\danie\\Miniconda2\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:170: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 cost 205.2613\n",
      "Epoch: 2 cost 43.4993\n",
      "Epoch: 3 cost 27.1512\n",
      "Epoch: 4 cost 19.0381\n",
      "Epoch: 5 cost 13.7564\n",
      "Epoch: 6 cost 10.3228\n",
      "Epoch: 7 cost 7.6124\n",
      "Epoch: 8 cost 5.7263\n",
      "Epoch: 9 cost 4.3452\n",
      "Epoch: 10 cost 3.2226\n",
      "Epoch: 11 cost 2.4786\n",
      "Epoch: 12 cost 1.8992\n",
      "Epoch: 13 cost 1.4759\n",
      "Epoch: 14 cost 1.2633\n",
      "Epoch: 15 cost 0.9352\n",
      "Epoch: 16 cost 0.7981\n",
      "Epoch: 17 cost 0.6729\n",
      "Epoch: 18 cost 0.5792\n",
      "Epoch: 19 cost 0.5335\n",
      "Epoch: 20 cost 0.4221\n",
      "Epoch: 21 cost 0.3441\n",
      "Epoch: 22 cost 0.4279\n",
      "Epoch: 23 cost 0.3753\n",
      "Epoch: 24 cost 0.3487\n",
      "Epoch: 25 cost 0.3565\n",
      "Epoch: 26 cost 0.2668\n",
      "Epoch: 27 cost 0.2535\n",
      "Epoch: 28 cost 0.3333\n",
      "Epoch: 29 cost 0.3373\n",
      "Epoch: 30 cost 0.3055\n",
      "Model has completed 30 Epochs of training\n"
     ]
    }
   ],
   "source": [
    "# 15 loops\n",
    "for epoch in range(training_epochs):\n",
    "    \n",
    "    # Cost\n",
    "    avg_cost = 0.\n",
    "    \n",
    "    total_batch = int(n_sample/batch_size) #num batches\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        \n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        # use underscore when don't need tuple unpacking in python\n",
    "        _,c = sess.run([optimizer,cost],feed_dict={x:batch_x,y:batch_y})\n",
    "        \n",
    "        avg_cost += c/total_batch\n",
    "        \n",
    "    print(\"Epoch: {} cost {:.4f}\".format(epoch+1,avg_cost))\n",
    "\n",
    "print(\"Model has completed {} Epochs of training\".format(training_epochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(pred,1),tf.argmax(y,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"strided_slice:0\", shape=(), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "print(correct_predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_predictions = tf.cast(correct_predictions,'float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"strided_slice_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(correct_predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(correct_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.Tensor"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95490003"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.eval({x:mnist.test.images,y:mnist.test.labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
